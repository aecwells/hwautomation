# GitHub Actions CI/CD Pipeline for HWAutomation
# This workflow runs on every push and pull request to ensure code quality
# and run comprehensive tests across multiple Python versions.

name: CI/CD Pipeline

# Trigger conditions
on:
  push:
    branches: [ main, develop ]
    tags: [ 'v*' ]
  pull_request:
    branches: [ main, develop ]

# Environment variables
env:
  PYTHON_DEFAULT_VERSION: "3.11"
  COVERAGE_THRESHOLD: 10

# Job definitions
jobs:
  # Code quality checks
  quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Fetch full history for better analysis

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
        cache: 'pip'

    - name: Check for frontend dependencies
      id: check-frontend
      run: |
        if [ -f "package.json" ]; then
          echo "frontend=true" >> $GITHUB_OUTPUT
        else
          echo "frontend=false" >> $GITHUB_OUTPUT
        fi

    - name: Set up Node.js
      if: steps.check-frontend.outputs.frontend == 'true'
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
        pip install black==24.4.2  # Pin black version for consistency

    - name: Install frontend dependencies
      if: steps.check-frontend.outputs.frontend == 'true'
      run: |
        npm ci

    - name: Check code formatting with Black
      run: |
        black --check --diff --line-length=88 --target-version=py39 src/ tests/

    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ tests/

    - name: Lint with flake8
      run: |
        flake8 src/ tests/

    - name: Type check with mypy
      run: |
        mypy src/ --show-error-codes --no-error-summary
      continue-on-error: true

    - name: Lint frontend code
      if: steps.check-frontend.outputs.frontend == 'true'
      run: |
        npm run lint

    - name: Check frontend formatting
      if: steps.check-frontend.outputs.frontend == 'true'
      run: |
        npm run format -- --check

    - name: Security scan with bandit
      run: |
        bandit -r src/ -f json -o bandit-report.json --configfile pyproject.toml
      continue-on-error: true

    - name: Upload security scan results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-scan-results
        path: bandit-report.json

  # Frontend build and tests
  frontend:
    name: Frontend Build
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Check for frontend dependencies
      id: check-frontend
      run: |
        if [ -f "package.json" ]; then
          echo "frontend=true" >> $GITHUB_OUTPUT
          echo "Frontend dependencies found"
        else
          echo "frontend=false" >> $GITHUB_OUTPUT
          echo "No frontend dependencies found, skipping frontend build"
        fi

    - name: Set up Node.js
      if: steps.check-frontend.outputs.frontend == 'true'
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install frontend dependencies
      if: steps.check-frontend.outputs.frontend == 'true'
      run: |
        npm ci

    - name: Build frontend assets
      if: steps.check-frontend.outputs.frontend == 'true'
      run: |
        npm run build

    - name: Upload frontend build artifacts
      if: steps.check-frontend.outputs.frontend == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: frontend-assets
        path: src/hwautomation/web/static/dist/

  # Unit tests
  test-unit:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Run unit tests
      run: |
        export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
        pytest tests/unit/

    - name: Upload coverage to Codecov
      if: matrix.python-version == env.PYTHON_DEFAULT_VERSION
      run: |
        # Download and install Codecov CLI
        curl -Os https://cli.codecov.io/latest/linux/codecov
        chmod +x codecov
        ./codecov --verbose upload-process --fail-on-error -t ${{ secrets.CODECOV_TOKEN }} -n 'unittests'-${{ github.run_id }} -F unittests -f coverage.xml

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}
        path: |
          junit.xml
          coverage.xml

  # Integration tests
  test-integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test-unit

    services:
      # Add any required services here (databases, etc.)
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_hwautomation
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Set up test database
      run: |
        # Create test database and run migrations if needed
        echo "Setting up test database..."

    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_hwautomation
      run: |
        export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
        pytest tests/ -m "integration" --tb=short --maxfail=5 --cov=src/hwautomation --cov-report=xml:coverage-integration.xml --cov-report=term-missing

    - name: Upload integration coverage to Codecov
      run: |
        # Download and install Codecov CLI
        curl -Os https://cli.codecov.io/latest/linux/codecov
        chmod +x codecov
        ./codecov --verbose upload-process --fail-on-error -t ${{ secrets.CODECOV_TOKEN }} -n 'integration'-${{ github.run_id }} -F integration -f coverage-integration.xml

    - name: Upload integration test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: |
          junit.xml
          coverage-integration.xml

  # Performance tests
  test-performance:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: test-unit
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Run performance tests
      run: |
        export PYTHONPATH="${PYTHONPATH}:$(pwd)/src"
        pytest tests/ -m "performance" --tb=short --cov=src/hwautomation --cov-report=xml:coverage-performance.xml --cov-report=term-missing

    - name: Upload performance coverage to Codecov
      run: |
        # Download and install Codecov CLI
        curl -Os https://cli.codecov.io/latest/linux/codecov
        chmod +x codecov
        ./codecov --verbose upload-process --fail-on-error -t ${{ secrets.CODECOV_TOKEN }} -n 'performance'-${{ github.run_id }} -F performance -f coverage-performance.xml

    - name: Generate performance report
      run: |
        python tools/quality/code_quality.py --coverage

    - name: Upload performance results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-test-results
        path: |
          htmlcov/
          performance-report.json
          coverage-performance.xml

  # Documentation checks
  docs:
    name: Documentation
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
        pip install sphinx sphinx-rtd-theme

    - name: Check documentation build
      run: |
        # Build documentation if we have Sphinx docs
        if [ -f "docs/conf.py" ]; then
          sphinx-build -b html docs/ docs/_build/html -W
        else
          echo "No Sphinx documentation found, checking README and other docs"
          # Check that key documentation files exist
          test -f README.md
          test -f docs/README.md
        fi

    - name: Check docstring coverage
      run: |
        interrogate src/ --fail-under=80 || echo "Docstring coverage below threshold"

  # Security and dependency checks
  security:
    name: Security Checks
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]

    - name: Run Safety CLI to check for vulnerabilities
      uses: pyupio/safety-action@v1
      with:
        api-key: ${{ secrets.SAFETY_API_KEY }}
        output-format: json
        args: "--save-as json safety-report.json"
      continue-on-error: true

    - name: Run additional security checks
      run: |
        bandit -r src/ -f json -o bandit-detailed.json
      continue-on-error: true

    - name: Upload security artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          safety-report.json
          bandit-detailed.json

  # Build and package
  build:
    name: Build Package
    runs-on: ubuntu-latest
    needs: [quality, test-unit, frontend]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_DEFAULT_VERSION }}
        cache: 'pip'

    - name: Check for frontend dependencies
      id: check-frontend
      run: |
        if [ -f "package.json" ]; then
          echo "frontend=true" >> $GITHUB_OUTPUT
        else
          echo "frontend=false" >> $GITHUB_OUTPUT
        fi

    - name: Set up Node.js
      if: steps.check-frontend.outputs.frontend == 'true'
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Install frontend dependencies and build
      if: steps.check-frontend.outputs.frontend == 'true'
      run: |
        npm ci
        npm run build

    - name: Build package
      run: |
        python -m build

    - name: Check package
      run: |
        twine check dist/*

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: package-artifacts
        path: dist/

  # Release deployment (only on tags)
  deploy:
    name: Deploy Release
    runs-on: ubuntu-latest
    needs: [quality, test-unit, test-integration, frontend, build]
    if: github.event_name == 'push' && startsWith(github.ref, 'refs/tags/v')

    environment:
      name: production
      url: https://pypi.org/project/hwautomation/

    steps:
    - name: Download build artifacts
      uses: actions/download-artifact@v4
      with:
        name: package-artifacts
        path: dist/

    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        password: ${{ secrets.PYPI_API_TOKEN }}

    - name: Create GitHub Release
      uses: actions/create-release@v1
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      with:
        tag_name: ${{ github.ref }}
        release_name: Release ${{ github.ref }}
        draft: false
        prerelease: false

  # Notification and reporting
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [quality, test-unit, test-integration, frontend, build]
    if: always()

    steps:
    - name: Notify on success
      if: ${{ needs.quality.result == 'success' && needs.test-unit.result == 'success' && needs.test-integration.result == 'success' && needs.frontend.result == 'success' && needs.build.result == 'success' }}
      run: |
        echo "üéâ All checks passed successfully!"

    - name: Notify on failure
      if: ${{ needs.quality.result == 'failure' || needs.test-unit.result == 'failure' || needs.test-integration.result == 'failure' || needs.frontend.result == 'failure' || needs.build.result == 'failure' }}
      run: |
        echo "‚ùå Some checks failed. Please review the results."
        exit 1

# Workflow configuration
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
